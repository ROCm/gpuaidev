# Anywhere {branch} is used, the branch name will be substituted.
# These comments will also be removed.
defaults:
  numbered: False
  maxdepth: 6
root: index
subtrees:

  - caption: Inference tutorials
    entries: 
    - file: notebooks/inference/build_airbnb_agent_mcp.ipynb
      title: AI Agent with MCPs using vLLM, and Pydantic AI
    - file: notebooks/inference/1_inference_ver3_HF_transformers.ipynb
      title: Hugging Face Transformers
    - file: notebooks/inference/2_inference_ver3_HF_TGI.ipynb
      title: Hugging Face TGI
    - file: notebooks/inference/3_inference_ver3_HF_vllm.ipynb
      title: Deploying with vLLM
    - file: notebooks/inference/rapbot_vllm.ipynb 
      title: From chatbot to rap bot with vLLM
    - file: notebooks/inference/rag_ollama_llamaindex.ipynb
      title: RAG with LlamaIndex and Ollama
    - file: notebooks/inference/ocr_vllm.ipynb
      title: OCR with vision-language models with vLLM
    - file: notebooks/inference/voice_pipeline_rag_ollama.ipynb
      title: Building AI pipelines for voice assistants
    - file: notebooks/inference/speculative_decoding_deep_dive.ipynb
      title: Speculative decoding with vLLM 
    - file: notebooks/inference/llama-stack-rocm.ipynb
      title: Llama Stack
    - file: notebooks/inference/deepseekr1_sglang.ipynb
      title: DeepSeek-R1 with SGLang

  - caption: Fine-tuning tutorials
    entries:
    - file: notebooks/fine_tune/fine_tuning_lora_qwen2vl.ipynb
      title: VLM with PEFT
    - file: notebooks/fine_tune/LoRA_Llama-3.2.ipynb
      title: LLM with LoRA
    - file: notebooks/fine_tune/QLoRA_Llama-3.1.ipynb
      title: LLM with QLoRA
    - file: notebooks/fine_tune/torchtune_llama3.ipynb
      title: Llama-3.1 8B with torchtune
    - file: notebooks/fine_tune/llama_factory_llama3.ipynb
      title: Llama-3.1 8B with Llama Factory
    - file: notebooks/fine_tune/unsloth_Llama3_1_8B_GRPO.ipynb
      title: GRPO with Unsloth

  - caption: Pretraining tutorials
    entries:
    - file: notebooks/pretrain/torch_fsdp.ipynb
      title: OLMo model with PyTorch FSDP
    - file: notebooks/pretrain/setup_tutorial.ipynb
      title: Training configuration with Megatron-LM
    - file: notebooks/pretrain/train_llama_mock_data.ipynb
      title: LLM with Megatron-LM
    - file: notebooks/pretrain/torchtitan_llama3.ipynb
      title: Llama-3.1 8B with torchtitan
    - file: notebooks/pretrain/ddim_pretrain.ipynb
      title: Custom Diffusion Model with PyTorch

  - caption: GPU Development and Optimization
    entries: 
    - file: notebooks/gpu_dev_optimize/triton_kernel_dev.ipynb
      title: Kernel Development & Optimizations with Triton
    - file: notebooks/gpu_dev_optimize/llama4_profiling_vllm.ipynb
      title: Profiling LLaMA 4 Inference with vLLM
    - file: notebooks/gpu_dev_optimize/fp8_quantization_quark_vllm.ipynb
      title: FP8 Quantization with AMD Quark for vLLM
  - caption: About
    entries:  
    - file: changelog.rst
      title: Changelog
    - file: notebooks/licensing.md
      title: Licensing and support information
