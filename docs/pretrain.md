# Pretraining Tutorials

The following tutorials cover pretraining the LLaMA model:

```{toctree}
:maxdepth: 1

notebooks/pretrain/dummy_notebook