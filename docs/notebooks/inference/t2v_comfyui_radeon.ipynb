{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c54efd",
   "metadata": {},
   "source": [
    "# Text-to-Video Generation with ComfyUI on Radeon GPU\n",
    "\n",
    "With the advancement of AIGC technology, the field of text-to-video and image-to-video generation have garnered widespread attention from visual designers, art enthusiasts, and media creators.\n",
    "\n",
    "ComfyUI is a ‌node-based graphical interface‌ designed for diffusion models, enabling users to visually construct AI image/video generation workflows through modular operations. Its modular node design, efficiency & compatibility and workflow advantage make it a perfect choice for media creators to ‌boost productivity.\n",
    "\n",
    "This tutorial guides you through setting up and running ComfyUI on AMD Radeon™ GPUs using ROCm™  software. Learn how to configure your environment, install the ComfyUI tool, and generate video from text on AMD consumer GPUs.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Operating System\n",
    "- **Ubuntu 22.04/24.04**: Ensure your system is running Ubuntu version 22.04 or 24.04.\n",
    "\n",
    "### Hardware\n",
    "- **AMD Radeon GPUs**: This tutorial was tested on an an AMD Radeon RX 7900 XTX GPU. Ensure you are using an AMD Radeon GPU or compatible hardware with ROCm support and that your system meets the [official requirements](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html).\n",
    "\n",
    "### Software\n",
    "- **ROCm 6.3**: Install and verify ROCm by following the [ROCm install guide](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/install/quick-start.html). After installation, confirm your setup using:\n",
    "\n",
    "    ```bash\n",
    "    rocm-smi\n",
    "    ```\n",
    "\n",
    "    This command lists your AMD GPUs with relevant details, similar to the image below:\n",
    "\n",
    "    ![rocm-smi output](../assets/comfyui-rocmsmi.png)\n",
    "\n",
    "## Setup ComfyUI\n",
    "\n",
    "To setup the ComfyUI inference environment, follow the steps below.\n",
    "\n",
    "### Prepare Inference Environment\n",
    "Create and activate a virtual environment by conda or venv.\n",
    "\n",
    "```bash\n",
    "conda create -n comfyui_env_test python=3.12\n",
    "conda activate comfyui_env_test\n",
    "```\n",
    "\n",
    "### Pytorch Installation\n",
    "Install Pytorch (ROCm) wheels in the virtual environment.\n",
    "\n",
    ">  \n",
    "> **Note**\n",
    ">\n",
    "> See [Install Pytorch for Radeon GPUs](https://rocm.docs.amd.com/projects/radeon/en/latest/docs/install/native_linux/install-pytorch.html) for install instructions.\n",
    ">  \n",
    "\n",
    "\n",
    "### Install and Launch Jupyter\n",
    "Inside the python virtual environment, install Jupyter using the following command:\n",
    "```bash\n",
    "pip install jupyter\n",
    "```\n",
    "Then start the Jupyter server:\n",
    "```bash\n",
    "jupyter-lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root\n",
    "```\n",
    "Note: Ensure port `8888` is not already in use on your system before running the above command. If it is, you can specify a different port by replacing `--port=8888` with another port number, for example, `--port=8890`.\n",
    "\n",
    "### Verify Pytorch Installation\n",
    "\n",
    "Verify if Pytorch is correctly installed.\n",
    "\n",
    "1. Verify if Pytorch is installed and detecting the GPU compute device.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -c 'import torch' 2> /dev/null && echo 'Success' || echo 'Failure'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c27cd1d",
   "metadata": {},
   "source": [
    "Expected result:\n",
    "\n",
    "``` bash\n",
    "Success\n",
    "```\n",
    "\n",
    "2. Test if the GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65231a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -c 'import torch; print(torch.cuda.is_available())'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e19d6a",
   "metadata": {},
   "source": [
    "Expected result:\n",
    "\n",
    "``` bash\n",
    "True\n",
    "```\n",
    "\n",
    "3. Display installed GPU device name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e935c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -c \"import torch; print(f'device name [0]:', torch.cuda.get_device_name(0))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8eed72",
   "metadata": {},
   "source": [
    "Expected result: Example: *device name [0]: Radeon RX 7900 XTX*\n",
    "``` bash\n",
    "device name[0]: <Supported AMD GPU>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9c01e",
   "metadata": {},
   "source": [
    "### ComfyUI Installation\n",
    "\n",
    "Install ComfyUI from source in linux system with AMD GPU.\n",
    "\n",
    "Git clone this repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b6e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/comfyanonymous/ComfyUI.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a7096",
   "metadata": {},
   "source": [
    "Make sure the Pytorch will not be reinstalled with CUDA version:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf465fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ComfyUI\n",
    "!sed -i.bak -E '/^(torch|torchaudio|torchvision)([<>=~!0-9.]*)?$/s/^/# /' requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bdfd3f",
   "metadata": {},
   "source": [
    "Install the dependancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c83bf4",
   "metadata": {},
   "source": [
    "## Running Text2Video Generation\n",
    "\n",
    "### Model Preparation\n",
    "\n",
    "LTX-Video is a efficient video model from lightricks. Ltx-video-2B-v0.9.5 is used here.\n",
    "\n",
    "Download the LTX-Video model [ltx-video-2b-v0.9.5.safetensors](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltx-video-2b-v0.9.5.safetensors) and text encoder model [t5xxl_fp16.safetensors](https://huggingface.co/Comfy-Org/mochi_preview_repackaged/blob/main/split_files/text_encoders/t5xxl_fp16.safetensors) files, and place these model files in `ComfyUI/models/checkpoints` and `ComfyUI/models/text_encoders` folder. All these can be done by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Define the URLs and destination paths\n",
    "models = {\n",
    "    \"https://huggingface.co/Lightricks/LTX-Video/resolve/main/ltx-video-2b-v0.9.5.safetensors\":\n",
    "        \"models/checkpoints/ltx-video-2b-v0.9.5.safetensors\",\n",
    "    \"https://huggingface.co/Comfy-Org/mochi_preview_repackaged/resolve/main/split_files/text_encoders/t5xxl_fp16.safetensors\":\n",
    "        \"models/text_encoders/t5xxl_fp16.safetensors\"\n",
    "}\n",
    "\n",
    "# Create target directories if they don't exist\n",
    "for path in models.values():\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "# Download files\n",
    "for url, path in models.items():\n",
    "    print(f\"Downloading {url} to {path}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    with open(path, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(f\"✅ Downloaded to {path}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527fc04",
   "metadata": {},
   "source": [
    "Different diffusion model pipeline may contain different submodels that should be placed into proper subfolders under ComfyUI/models.\n",
    "\n",
    "### Launch\n",
    "\n",
    "Launch the ComfyUI server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc33086c",
   "metadata": {},
   "source": [
    "After the server launched, the log will show:\n",
    "\n",
    "```\n",
    " Starting server\n",
    "\n",
    " To see the GUI go to: http://127.0.0.1:8188\n",
    "```\n",
    "\n",
    "Copy the address http://127.0.0.1:8188 and paste it into browser, the page will show a default workflow which looks like:\n",
    "![default workflow](../assets/comfyui-default-json.png)\n",
    "\n",
    "### Load Workflow\n",
    "\n",
    "ComfyUI's workflow defines the full pipeline and parameters used to generate image or video. It is formatted as a json file or encoded in a webp animated image (*.webp). Users can construct their own workflow from scratch or customize the workflow from third party.\n",
    "\n",
    "Download the LTX-Video's text-to-video workflow (*.json or *.webp) from [example page](https://comfyanonymous.github.io/ComfyUI_examples/ltxv/), load it or drag it on the ComfyUI GUI, the loaded workflow looks like below:\n",
    "\n",
    "![ltx workflow](../assets/comfyui-ltx-workflow.png)\n",
    "\n",
    "The workflow is composed by different nodes, each of which has different functionality.\n",
    "\n",
    "The `Load Checkpoint` node is in charge of diffusion model loading. The ckpt_name field could be changed if there were other diffusion models available.\n",
    "\n",
    "The `Load Image` node is in charge of loading the input image. You can upload the required image using this node.\n",
    "\n",
    "The `CLIP TEXT Encode (Positive Prompt)` node is a placeholder for positive prompt. Users can change it to their own. Here is the prompt:\n",
    "> A drone quickly rises through a bank of morning fog, revealing a pristine alpine lake surrounded by snow-capped mountains. The camera glides forward over the glassy water, capturing perfect reflections of the peaks. As it continues, the perspective shifts to reveal a lone wooden cabin with a curl of smoke from its chimney, nestled among tall pines at the lake's edge. The final shot tracks upward rapidly, transitioning from intimate to epic as the full mountain range comes into view, bathed in the golden light of sunrise breaking through scattered clouds.\n",
    "\n",
    "The `EmptyLTXVLatentVideo` node is used to control the generated video's frame size and length.\n",
    "\n",
    "More information about ComfyUI Nodes are  found at [ComfyUI Wik](https://comfyui-wiki.com/en/comfyui-nodes).\n",
    "\n",
    "### Run Inference\n",
    "\n",
    "Once the workflow is ready, simply click the button \"Run\" to initiate the whole pipleline to process. The log output of the inference will be:\n",
    "```\n",
    " got prompt\n",
    " model weight dtype torch.bfloat16, manual cast: None\n",
    " model_type FLUX\n",
    " VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n",
    " no CLIP/text encoder weights in checkpoint, the text encoder model will not be loaded.\n",
    " CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cpu, dtype: torch.float16\n",
    " Requested to load MochiTEModel_\n",
    " loaded completely 23280.8 9083.38671875 True\n",
    " Requested to load LTXV\n",
    " loaded completely 10667.71279296875 3667.902587890625 True\n",
    " 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.46s/it]\n",
    " Requested to load VideoVAE\n",
    " loaded completely 5763.6171875 4756.450138092041 True\n",
    " Warning: Ran out of memory when regular VAE decoding, retrying with tiled VAE decoding.\n",
    " Prompt executed in 66.29 seconds\n",
    "```\n",
    "\n",
    "The final output video will be shown in SaveAnimatedWEBP node:\n",
    "\n",
    "![ltx output](../assets/comfyui-output.webp)\n",
    "\n",
    "The final output *.webp file is located at `ComfyUI/output/` folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
