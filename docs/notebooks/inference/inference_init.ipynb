{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bdc7a27",
   "metadata": {},
   "source": [
    "# LLM Inference with AMD Instinct ™ MI300X Accelerators   \n",
    "add introduction\n",
    "\n",
    "## Prerequisites\n",
    "### 1.Hardware Requirements\n",
    "-AMD ROCm GPUs (e.g., MI210, MI300X).\n",
    "-Ensure your system meets the System Requirements, including ROCm 6.0+ and Ubuntu 22.04.\n",
    "### 2.Docker\n",
    "-Install Docker with GPU support\n",
    "-Ensure your user has appropriate permission to access to GPU\n",
    "\n",
    "```bash\n",
    "docker run --rm --device=/dev/kfd --device=/dev/dri rocm/pytorch:rocm6.1_ubuntu22.04_py3.10_pytorch_2.1.2 rocm-smi\n",
    "```\n",
    "### 3.Hugging Face API Access\n",
    "-Obtain an API token from Hugging Face for downloading models.\n",
    "-Ensure you have a Hugging Face API token with the necessary permissions and approval to access Meta’s LLaMA checkpoints.\n",
    "\n",
    "## Prepare Inference Environment\n",
    "### 1.Pull the Docker Image\n",
    "```bash\n",
    "# Host machine\n",
    "docker run -it --rm --device=/dev/kfd --device=/dev/dri --group-add video --shm-size 1G --security-opt seccomp=unconfined --security-opt apparmor=unconfined -v $(pwd):/workspace --env HUGGINGFACE_HUB_CACHE=/workspace rocm/pytorch:latesti\n",
    "\n",
    "# Inside the container \n",
    "cd /workspace \n",
    "export HF_TOKEN=\"Your hugging face token to access gated models\" \n",
    "pip install accelerate transformers \n",
    "```\n",
    "\n",
    "### 2.Install and Launch Jupyter\n",
    "Inside the Docker container, install Jupyter using the following command:\n",
    "```bash\n",
    "pip install --upgrade pip setuptools wheel\n",
    "pip install jupyter\n",
    "```\n",
    "Start the Jupyter server:\n",
    "```bash\n",
    "jupyter-lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root\n",
    "```\n",
    "### 3.Run a Sample LLM\n",
    "Create a hf_transformer.py file inside the docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b9baa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# hf_transformers.py\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m  \n\u001b[1;32m      5\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3.1-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# hf_transformers.py\n",
    "import transformers\n",
    "import torch  \n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "pipeline = transformers.pipeline( \n",
    "    \"text-generation\", \n",
    "    model=model_id, \n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16}, \n",
    "    device_map=\"auto\", \n",
    ") \n",
    "\n",
    "messages = [ \n",
    "    {\"role\": \"system\", \"content\": \"You are a chatbot in the online shopping mall!\"}, \n",
    "    {\"role\": \"user\", \"content\": \"How can I get a refund of this product?\"}, \n",
    "] \n",
    "\n",
    "outputs = pipeline( \n",
    "    messages,\n",
    "    max_new_tokens=10, \n",
    ") \n",
    "\n",
    "print(outputs[0][\"generated_text\"][-1]) \n",
    "\n",
    "# python hf_transformers.py \n",
    "# gives \n",
    "{'role': 'assistant', 'content': \"I'd be happy to help you with the refund\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
