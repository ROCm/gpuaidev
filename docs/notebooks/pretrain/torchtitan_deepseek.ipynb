{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b94c80-48ff-467c-9da4-83594c879312",
   "metadata": {},
   "source": [
    "#  Pretraining with TorchTitan\n",
    "\n",
    "This tutorial is designed for [AMD Developer Cloud](https://www.amd.com/en/developer/resources/cloud-access/amd-developer-cloud.html) users who have access to a single-node environment, for example, an 8-GPU system.\n",
    "It demonstrates an end‑to‑end, single‑box training workflow using the TorchTitan AMD fork on ROCm.\n",
    "\n",
    "**What you’ll learn**\n",
    "\n",
    "How to:\n",
    "\n",
    "- Set up a clean single-node training environment.\n",
    "- Launch TorchTitan on a mixture of experts (MoE) configuration and understand the key flags.\n",
    "- Monitor the logs and verify the run.\n",
    "\n",
    "**TorchTitan**\n",
    "\n",
    "TorchTitan is a compact proof of concept that demonstrates the newest native PyTorch-distributed APIs.\n",
    "The AMD fork adds full ROCm support and experimental Primus-Turbo `FP8` kernels.\n",
    "This tutorial uses the `dev/primus_turbo` branch of the [AMD-AGI/torchtitan-amd](https://github.com/AMD-AGI/torchtitan-amd) repository.\n",
    "\n",
    "**The model**\n",
    " \n",
    "DeepSeek‑MoE 16B Base (with approximately 16.4B parameters) is an MoE LLM with fine‑grained experts and shared‑expert isolation.\n",
    "The Hugging Face model card is [deepseek-moe-16b-base](https://huggingface.co/deepseek-ai/deepseek-moe-16b-base).\n",
    "\n",
    "**The goal**\n",
    "\n",
    "Obtain a successful single‑node run with clear logging and checks, so you can confidently scale or swap datasets later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a574fe-6a51-4151-a1ea-032bfc0e811c",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial was developed and tested using the following setup.\n",
    "\n",
    "### Operating system\n",
    "\n",
    "* **Ubuntu 22.04**: Ensure your system is running Ubuntu 22.04.\n",
    "\n",
    "### Hardware\n",
    "\n",
    "* **AMD Instinct™ GPUs**: This tutorial was validated on an AMD Instinct MI300X node (with 8 GPUs). Ensure you are using an AMD Instinct GPU or compatible hardware with ROCm support and that your system meets the [official requirements](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html).\n",
    "\n",
    "### Software\n",
    "\n",
    "* **ROCm 6.3 or later**: Install and verify ROCm by following the [ROCm install guide](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/install/quick-start.html). After installation, confirm your setup using:\n",
    "\n",
    "   ``` bash\n",
    "   amd-smi\n",
    "   ```\n",
    "\n",
    "   This command lists your AMD GPUs with relevant details.\n",
    "   \n",
    "   **Note**: For ROCm 6.4 and earlier, use the `rocm-smi` command instead.\n",
    "  \n",
    "* **Docker**: Ensure Docker is installed and configured correctly. Follow the Docker installation guide for your operating system.\n",
    "\n",
    "   **Note**: Ensure the Docker permissions are correctly configured. To configure permissions to allow non-root access, run the following commands:\n",
    "\n",
    "   ``` bash\n",
    "   sudo usermod -aG docker $USER\n",
    "   newgrp docker\n",
    "   ```\n",
    "\n",
    "   Verify Docker is working correctly:\n",
    "   \n",
    "\n",
    "   ``` bash\n",
    "   docker run hello-world\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a14fea-5be6-431e-bbc6-8a508f7037c7",
   "metadata": {},
   "source": [
    "## Prepare the training environment\n",
    "\n",
    "To set up your training environment, follow these steps:\n",
    "\n",
    "### 1. Pull the Docker image\n",
    "\n",
    "Ensure your system meets the [ROCm system requirements](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html).\n",
    "\n",
    "Pull the Docker image required for this tutorial:\n",
    "\n",
    "``` bash\n",
    "docker pull docker.io/rocm/primus:v25.9_gfx942\n",
    "```\n",
    "\n",
    "### 2. Launch the Docker container\n",
    "\n",
    "Launch the Docker container and map the necessary directories.\n",
    "\n",
    "``` bash\n",
    "docker run -it --rm \\\n",
    "  --name torchtitan_tutorial \\\n",
    "  --device /dev/dri --device /dev/kfd \\\n",
    "  --network host --ipc host --group-add video \\\n",
    "  --cap-add SYS_PTRACE --security-opt seccomp=unconfined --privileged \\\n",
    "  -v \"$PWD\":/workspace \\\n",
    "  -w /workspace \\\n",
    "  --entrypoint /bin/bash \\\n",
    "  docker.io/rocm/primus:v25.9_gfx942\n",
    "```\n",
    "\n",
    "**Note**: This command mounts the current directory to the `/workspace` directory in the container. Ensure the notebook file is either copied to this directory before running the Docker command or uploaded into the Jupyter Notebook environment after it starts. Save the token or URL provided in the terminal output to access the notebook from your web browser. You can download this notebook from the [AI Developer Hub GitHub repository](https://github.com/ROCm/gpuaidev).\n",
    "\n",
    "### 3. Install and launch Jupyter\n",
    "\n",
    "Inside the Docker container, install Jupyter using the following command:\n",
    "\n",
    "``` bash\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "Start the Jupyter server:\n",
    "\n",
    "``` bash\n",
    "jupyter lab --ip=127.0.0.1 --port=8888 --no-browser --allow-root\n",
    "```\n",
    "\n",
    "**Note**: Ensure port `8888` is not already in use on your system before running the above command. If it is, you can specify a different port by replacing `--port=8888` with another port number, for example, `--port=8890`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92158cb3-c91d-460d-8def-649c1f7ea94d",
   "metadata": {},
   "source": [
    "### 4. Set up the environment\n",
    "\n",
    "Now, set up the environment using single‑node defaults by disabling InfiniBand (IB) and clearing the Slurm variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc35a193-d154-49d6-be14-a2f32f8df781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- export env vars ---\n",
    "os.environ[\"NCCL_SOCKET_IFNAME\"] = \"lo\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "os.environ.pop(\"SLURM_MASTER_ADDR\", None)\n",
    "os.environ.pop(\"SLURM_MASTER_PORT\", None)\n",
    "\n",
    "# --- verify ---\n",
    "print(\"NCCL_SOCKET_IFNAME =\", os.environ[\"NCCL_SOCKET_IFNAME\"])\n",
    "print(\"NCCL_IB_DISABLE =\", os.environ[\"NCCL_IB_DISABLE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b435469a-d43f-4fcf-8524-f4647bf0c84a",
   "metadata": {},
   "source": [
    "### 5. Clone and install TorchTitan and Primus-Turbo inside the container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddcb16b-24a2-45c5-91dd-f3fa0714fe48",
   "metadata": {},
   "source": [
    "Use Git to clone the TorchTitan AMD fork (or update it, if it already exists) and checkout the `Primus-Turbo` branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64891e87-f21b-48e1-9de1-80cdd3b45682",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "if [ -d \"torchtitan-amd/.git\" ]; then\n",
    "  echo \"[info] Repo exists: torchtitan-amd\"\n",
    "else\n",
    "  echo \"[info] Cloning https://github.com/AMD-AIG-AIMA/torchtitan-amd.git ...\"\n",
    "  git clone \"https://github.com/AMD-AIG-AIMA/torchtitan-amd.git\"\n",
    "fi\n",
    "\n",
    "cd torchtitan-amd\n",
    "git checkout dev/primus_turbo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb973eb-7255-4bb6-a284-f8333c49ff83",
   "metadata": {},
   "source": [
    "Create per‑host build caches for the AITER and PyTorch extensions to avoid permission collisions between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b937cc9-9931-46fb-8401-4bebfda23d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "from pathlib import Path\n",
    "\n",
    "# --- unset env vars  ---\n",
    "os.environ.pop(\"AITER_JIT_DIR\", None)\n",
    "os.environ.pop(\"TORCH_EXTENSIONS_DIR\", None)\n",
    "\n",
    "# --- hostname  ---\n",
    "host_name = socket.gethostname()\n",
    "\n",
    "# --- build dir ---\n",
    "tmp_build_dir = Path(\"/workspace/torchtitan-amd/3rdparty/build\") / host_name\n",
    "tmp_build_dir.mkdir(parents=True, exist_ok=True)   # like `mkdir -p ...`\n",
    "\n",
    "# --- export env vars ---\n",
    "os.environ[\"AITER_JIT_DIR\"] = str(tmp_build_dir / \"single_aiter_cache\")\n",
    "os.environ[\"TORCH_EXTENSIONS_DIR\"] = str(tmp_build_dir / \"torch_extensions\")\n",
    "\n",
    "# --- verify ---\n",
    "print(\"AITER_JIT_DIR =\", os.environ[\"AITER_JIT_DIR\"])\n",
    "print(\"TORCH_EXTENSIONS_DIR =\", os.environ[\"TORCH_EXTENSIONS_DIR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f0301-a0f1-4e17-9e39-1d978f8de564",
   "metadata": {},
   "source": [
    "Install TorchTitan inside the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ddfd6d-ec3c-48d2-a7d1-410a5c3768ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "cd torchtitan-amd\n",
    "\n",
    "pip install -r requirements.txt\n",
    "pip install torchao\n",
    "pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c898ebe-946b-4862-b74c-72857c01f054",
   "metadata": {},
   "source": [
    "Install Primus-Turbo from the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ba6acec-dbd8-433b-b4ea-2b4dc549a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "cd torchtitan-amd\n",
    "\n",
    "pip uninstall numpy -y && pip install numpy==1.26.4\n",
    "pip3 install --extra-index-url https://test.pypi.org/simple ./3rdparty/primus_turbo-0.1.0+dbeaf79-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6cdc3e-fa59-44db-a67d-34ae74fae690",
   "metadata": {},
   "source": [
    "### 6. Download the DeepSeekMoE 16B base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6811143-b396-4074-a525-ca3cdf890a6a",
   "metadata": {},
   "source": [
    "Download the `deepseek-ai/deepseek-moe-16b-base` model from Hugging Face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c0866-9734-4d6b-abad-94ba2c6890f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "cd torchtitan-amd\n",
    "python scripts/download_hf_assets.py --repo_id deepseek-ai/deepseek-moe-16b-base --assets tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f990f72-134d-4c0e-afda-a204cfe37153",
   "metadata": {},
   "source": [
    "## Create the training configuration\n",
    "\n",
    "Follow these steps to create a configuration file to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b276b-3cc2-4322-8a0b-bb7420ea9d2d",
   "metadata": {},
   "source": [
    "### 1. Create a working copy of the TOML configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2f090-6fef-4e07-8c36-219bbd9f623e",
   "metadata": {},
   "source": [
    "Create a working copy of the base configuration file for the DeepSeekMoE 16B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "960459fe-c041-4272-8400-5afe6dff00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, shutil\n",
    "\n",
    "repo_dir = pathlib.Path(\"torchtitan-amd\")\n",
    "\n",
    "override_dir = repo_dir / \"run_configs\"\n",
    "override_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "base_config_path = repo_dir / \"torchtitan/models/deepseek_v3/train_configs/deepseek_v3_16b.toml\"\n",
    "override_config_path = override_dir / \"deepseek_v3_16b_local.toml\"\n",
    "\n",
    "shutil.copyfile(base_config_path, override_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16232d7f-dea9-4334-b488-e48f63b5a700",
   "metadata": {},
   "source": [
    "### 2. Modify the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcdb6f6-6742-4079-9bb6-b7bdc53f05ec",
   "metadata": {},
   "source": [
    "Install `tomlkit`, a tool for patching the TOML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7e25be7-a240-4429-8719-93efc5b05e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tomlkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde17883-816b-4892-aac7-ac1907fa7c5a",
   "metadata": {},
   "source": [
    "Next, modify the configuration file to suit your training.\n",
    "For this tutorial, choose the following settings:\n",
    "\n",
    "```toml\n",
    "[profiling]\n",
    "enable_profiling = false     # Profiling disabled. Enable it if you need the traces.\n",
    "\n",
    "[training]\n",
    "local_batch_size = 32        # Edit for a different batch size.\n",
    "steps = 10                   # Training for only 10 steps. Increase this for real training.\n",
    "dataset = \"c4_test\"          # This is a small sample dataset. Use `\"c4\"` for a real HF dataset.\n",
    "\n",
    "[parallelism]\n",
    "expert_parallel_degree = 8   # Edit for a different expert parallel degree.\n",
    "\n",
    "[checkpoint]\n",
    "enable = false               # Checkpointing disabled. Enable it for real training.\n",
    "```\n",
    "\n",
    "**Optional**: Edit the following block for different configurations. You can modify other fields as well. Review the output from the next cell to see all fields in the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68641b7b-face-4e55-a74a-f508abb228c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomlkit\n",
    "\n",
    "doc = tomlkit.parse(override_config_path.read_text())\n",
    "\n",
    "# profiling\n",
    "doc[\"profiling\"][\"enable_profiling\"]         = False\n",
    "\n",
    "# training\n",
    "doc[\"training\"][\"local_batch_size\"]          = 32\n",
    "doc[\"training\"][\"dataset\"]                   = \"c4_test\"\n",
    "doc[\"training\"][\"steps\"]                     = 10\n",
    "\n",
    "# parallelism\n",
    "doc[\"parallelism\"][\"expert_parallel_degree\"] = 8\n",
    "\n",
    "# checkpoint\n",
    "doc[\"checkpoint\"][\"enable\"]                  = False\n",
    "\n",
    "override_config_path.write_text(tomlkit.dumps(doc))\n",
    "\n",
    "print(\"Working config:\", str(override_config_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9521e857-e218-4933-9b8b-d0f7264512df",
   "metadata": {},
   "source": [
    "View the resulting TOML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246b25b4-1e9c-49af-9c34-2840317f59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "text = override_config_path.read_text()\n",
    "display(Markdown(f\"```toml\\n{text}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b4153-599d-4467-ae52-9ebb3043b9de",
   "metadata": {},
   "source": [
    "### 3. Set the environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce72c3d-5819-4621-aad8-e0f9db218395",
   "metadata": {},
   "source": [
    "Set the environment variable `CONFIG_FILE` to point to your working copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "960c7d99-8ae7-4938-bd05-322fcd4fcad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, os\n",
    "\n",
    "config_path = override_config_path.resolve().relative_to(pathlib.Path(\"/workspace/torchtitan-amd\"))\n",
    "\n",
    "# --- export env vars ---\n",
    "os.environ[\"CONFIG_FILE\"] = str(config_path)\n",
    "\n",
    "# --- verify ---\n",
    "print(\"CONFIG_FILE =\", os.environ[\"CONFIG_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7a8bc-b45e-4e3d-8c13-db9bfcd981ef",
   "metadata": {},
   "source": [
    "## Pretrain the model\n",
    "\n",
    "This section explains how to train the model and verify the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9fb10-fa03-4b5b-aec4-d05b07661577",
   "metadata": {},
   "source": [
    "### 1. Start training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c749ab1-8dd3-4152-834c-22e799e16756",
   "metadata": {},
   "source": [
    "You can now run the training script.\n",
    "It might take a few minutes for AITER to build. After training starts, it prints metrics for each step.\n",
    "To verify the results of the run later, save the logs to `logs/dsv3_16b_$(date +%Y%m%d_%H%M%S).log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb2d5c68-69f2-4f90-aff7-c3fb8b60a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "cd torchtitan-amd\n",
    "mkdir -p logs\n",
    "\n",
    "export PYTHONUNBUFFERED=1\n",
    "stdbuf -oL -eL ./run_train.sh 2>&1 | tee -a logs/dsv3_16b_$(date +%Y%m%d_%H%M%S).log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ca87ef-6b1f-4e63-b73f-6e2b960dc7bb",
   "metadata": {},
   "source": [
    "### 2. Verify the run results\n",
    "\n",
    "Finally, you can extract the step, loss, and tokens from logs. You should expect the loss to decrease slightly within the first few steps on the sample data and the tokens to be non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185be75c-6a52-43f3-bdb7-74aa650da9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pathlib, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "log_dir = pathlib.Path(\"./torchtitan-amd/logs\")  # adjust if needed\n",
    "log_files = sorted(log_dir.glob(\"**/*.log\")) + sorted(log_dir.glob(\"**/*.out\"))\n",
    "assert log_files, f\"No logs found in {log_dir.resolve()}\"\n",
    "lf = max(log_files, key=lambda p: p.stat().st_mtime)  # newest\n",
    "\n",
    "# Strip ANSI color codes\n",
    "ansi_re = re.compile(r\"\\x1B\\[[0-?]*[ -/]*[@-~]\")\n",
    "\n",
    "# Tolerant metrics line (handles commas in numbers and both 'tps' or 'tokens/s')\n",
    "metrics_re = re.compile(\n",
    "    r\"step:\\s*(\\d+).*?\"\n",
    "    r\"loss:\\s*([-\\d.eE+]+).*?\"\n",
    "    r\"grad_norm:\\s*([-\\d.eE+]+).*?\"\n",
    "    r\"memory:\\s*([-\\d.eE+]+)GiB\\(([-\\d.eE+]+)%\\).*?\"\n",
    "    r\"(?:tps|tokens/s):\\s*([\\d.,eE+-]+).*?\"\n",
    "    r\"tflops:\\s*([-\\d.eE+]+).*?\"\n",
    "    r\"mfu:\\s*([-\\d.eE+]+)%\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for raw in lf.read_text(errors=\"ignore\").splitlines():\n",
    "    line = ansi_re.sub(\"\", raw)\n",
    "    m = metrics_re.search(line)\n",
    "    if m:\n",
    "        step = int(m.group(1))\n",
    "        loss = float(m.group(2))\n",
    "        grad = float(m.group(3))\n",
    "        mem_gib = float(m.group(4))\n",
    "        mem_pct = float(m.group(5))\n",
    "        tps = float(m.group(6).replace(\",\", \"\"))  # remove thousands commas\n",
    "        tflops = float(m.group(7))\n",
    "        mfu = float(m.group(8))\n",
    "        rows.append({\n",
    "            \"step\": step, \"loss\": loss, \"grad_norm\": grad,\n",
    "            \"mem_gib\": mem_gib, \"mem_%\": mem_pct,\n",
    "            \"tps\": tps, \"tflops\": tflops, \"mfu_%\": mfu\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"step\").drop_duplicates(\"step\")\n",
    "display(df.tail(10))\n",
    "\n",
    "# Quick health checks\n",
    "if not df.empty:\n",
    "    print(f\"Steps parsed: {df.step.min()}..{df.step.max()} ({len(df)} points)\")\n",
    "    if len(df) >= 2 and df[\"loss\"].iloc[-1] <= df[\"loss\"].iloc[0]:\n",
    "        print(\"✓ Loss decreased at least once — smoke test looks healthy.\")\n",
    "    else:\n",
    "        print(\"! Loss didn’t drop yet — tiny sample data can wobble; let a few more steps run.\")\n",
    "\n",
    "# Plots\n",
    "plt.figure()\n",
    "plt.plot(df[\"step\"], df[\"loss\"])\n",
    "plt.xlabel(\"step\"); plt.ylabel(\"loss\"); plt.title(\"Loss vs step\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df[\"step\"], df[\"tps\"])\n",
    "plt.xlabel(\"step\"); plt.ylabel(\"tokens/sec (tps)\"); plt.title(\"Throughput vs step\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: confirm training ended\n",
    "finished = \"Training completed\" in ansi_re.sub(\"\", lf.read_text(errors=\"ignore\"))\n",
    "print(\"Finished flag:\", \"✓\" if finished else \"—\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
